# Decodifi AI Starter

## Step-by-step setup

[Create a new repository from this template](https://github.com/new?template_name=ai-starter&template_owner=decodifi-tyler)

### Install dependencies

```bash
bun i
```

### Run the local database

```bash
bun run supabase:start
```

### Run the development server

```bash
bun dev
```

You now have a local supabase instance running and a development server. There is a default user created with the email `admin@decodifi.uk` and the password `mHMGB1uzkdfQ16xU`.


## Database Management with Drizzle

This project uses [Drizzle ORM](https://orm.drizzle.team) in combination with [Supabase](https://supabase.com) for managing the database schema in a version controlled way.

### Database Schema

The database schema is defined in TypeScript under `supabase/schemas/index.ts`. This is where you define all your tables, columns, and relationships. As your project grows, you can split the schema into multiple files.

### RLS Policies

**IMPORTANT:** All tables require an RLS policy to be defined. Without this, all data in the table will be public even to unauthenticated users.

The RLS policies are defined with your tables in the schema as follows:

```typescript
export const posts = pgTable('posts', {
  id: uuid('id').primaryKey(),
  authorId: uuid('author_id').notNull().references(() => users.id),
  title: text('title').notNull(),
  content: text('content').notNull(),
}, t => [
  crudPolicy({
    // All authenticated users can read
    read: true,
    // Only the author can modify
    modify: sql`author_id = auth.uid()`,
    role: authenticatedRole,
  }),
  crudPolicy({
    // All users can read
    read: true,
    // No unauthenticated user can modify
    modify: false,
    role: anonRole,
  })
]);
```
 
### Making Schema Changes

To modify the database schema:

1. Edit the schema definitions in `supabase/schemas/index.ts`
2. Generate a migration:

```bash
bun run db:diff
```

This will create a new migration file in `supabase/migrations` that contains SQL to update your database.

Note: If you make a mistake or the migration fails to apply, you can run `npx drizzle-kit drop` to remove a migration.

3. Apply the migration:

```bash
bun run db:migrate
```

4. Regenerate the types:

```bash
bun run supabase:generate-types
```

This will generate the types in the `utils/supabase/types.ts` file. You only need to do this if you make changes to the properties of the tables.

This will execute the migration SQL against your database.

### Managing Buckets

Buckets are managed in the `supabase/schemas/buckets/index.sql` file. Buckets in Supabase are defined in the `storage.buckets` table, and the files in the buckets are represented by rows in the `storage.objects` table. There is no way to reference these tables in drizzle so the schema for the buckets is managed in a separate sql file. Because of this, migrations must be generated using a different workflow to the one defined above.

#### Why is this so complicated?

The benefit of all this is that the buckets can be version controlled, meaning different branches can have different buckets and policies. Drizzle is only configured the manage the public schema, and doesn't have the ability to insert rows, which limits it's usefulness for managing buckets. This process uses the standard supabase delcarative schemas approach, but includes a few additional steps to make everything compatible with the drizzle migrations.

#### Creating a new bucket

To create a new bucket, add a new record to the `storage.buckets` table and a policy to the `storage.objects` table. Bucket names must follow the s3 bucket naming convention, which is a lowercase alphanumeric dash separated string. Bucket names must be unique.

```sql
-- /supabase/schemas/buckets/index.sql
-- ... other SQL statements
insert into storage.buckets (id, name, public) values ('example-bucket-name', 'example-bucket-name', true);
create policy "Allow authenticated users to access example-bucket-name bucket" on storage.objects for all
    using (bucket_id = 'example-bucket-name' and auth.role() = 'authenticated')
    with check (bucket_id = 'example-bucket-name' and auth.role() = 'authenticated');
```
**Important note**: Make sure to update your RLS policies to allow access only to users under the correct conditions. A common pattern is to allow users access to files inside a folder that matches their user ID, or an ID of a group or organisation they belong to. Please refer to the [supabase documentation](https://supabase.com/docs/guides/storage/security/access-control) for more information and useful examples.

Then use this command to generate a new empty drizzle migration:

```bash
bun run db:diff --custom
```

Make a note of the name of the file generated by the above command, then run the following commands to generate the migration code (making sure to replace `0000_FILENAME` with the name of the file you just noted):

```bash
bunx supabase stop # If you don't do this, the next command will report that there are no schema changes
bunx supabase db diff --schemas storage > supabase/migrations/0000_FILENAME.sql
```

This will populate the migration file you just generated to contain the SQL to add the RLS policies, but because buckets are defined as a row in the `storage.buckets` table, we need to add the bucket insertion statement manually to the top of the migration file.

Copy the first line of the schema changes we made above and paste it at the top of the migration file you just generated.

```sql
insert into storage.buckets (id, name, public) values ('example-bucket-name', 'example-bucket-name', true);

-- ...The RLS policy definition/modification generated by drizzle...
```

Finally, apply the migration to the local database:

```bash
bunx supabase start
bunx supabase db push --local
```
Note: If you get a message saying `ERROR: invalid byte sequence for encoding "UTF8": 0xff (SQLSTATE 22021)`, the migration file was generated an invalid encoding, and you will need to manually update the file to be valid UTF-8.

#### Making changes to bucket policies

Because the bucket is defined in an earlier migration, making changes to the bucket policies allows you to directly use the generated migration code. All we need to do is make sure the migration is registered in drizzle.

Simply edit the policies in the `supabase/schemas/buckets/index.sql` file. Then run the following command to generate a new migration:

```bash
bun run db:diff --custom
```

Make a note of the name of the file generated by the above command, then run the following commands to generate the migration code (making sure to replace `0000_FILENAME` with the name of the file you just noted):

```bash
bunx supabase stop
bunx supabase db diff --schemas storage > supabase/migrations/0000_FILENAME.sql
```

Finally, apply the migration to the local database:

```bash
bunx supabase start
bunx supabase db push --local
```

Note: If you get a message saying `ERROR: invalid byte sequence for encoding "UTF8": 0xff (SQLSTATE 22021)`, the migration file was generated an invalid encoding, and you will need to manually update the file to be valid UTF-8.

#### Deleting a bucket

To delete a bucket, remove the bucket insertion and policies from the `supabase/schemas/buckets/index.sql` file and run the following command to generate a new empty migration with drizzle:

```bash
bun run db:diff --custom
```

Make a note of the name of the file generated by the above command, then run the following commands to generate the migration code (making sure to replace `0000_FILENAME` with the name of the file you just noted):

```bash
bunx supabase stop
bunx supabase db diff --schemas storage > supabase/migrations/0000_FILENAME.sql
```

This will populate the migration file you just generated to contain the SQL to remove the RLS policies, but because buckets are defined in an earlier migration, we need to add the bucket deletion statement manually to the top of the migration file.

Add the bucket deletion statement to the top of the migration file you just generated:

```sql
delete from storage.buckets where id = 'example-bucket-name';

-- ...The RLS policy deletion generated by drizzle...
```

Finally, apply the migration to the local database:

```bash
bunx supabase start
bunx supabase db push --local
```

Note: If you get a message saying `ERROR: invalid byte sequence for encoding "UTF8": 0xff (SQLSTATE 22021)`, the migration file was generated an invalid encoding, and you will need to manually update the file to be valid UTF-8.

### Using in Your Application

The project uses Next.js SSR to improve loading performance. To accomplish this, we gather all data required for the initial page load in the page file. Then all subsequent data is fetched from the client.

For more information on how to use the supabase client in your application, please refer to the [supabase hook documentation](./utils/supabase/README.md).

## Testing

We use [Playwright](https://playwright.dev) for E2E testing. The tests run in a test database that is automatically created and dropped when the tests are run.

### Running tests

```bash
bun run test
```

### Writing tests

We use the `test` directory to write our tests. Each file in the `test` directory is treated as a test file.

I would reccommend at least having two tests for each CRUD operation. One to test users that should be allowed access, and one to test users that should be denied access.

If you experience bugs, it is a good approach to create a test that reproduces the bug and then fix the bug. This allows AI to work until the bug is fixed.

## Configuring production infrastructure

### Deploying to Vercel

```bash
# bun dlx vercel login
# bun dlx vercel link
# bun dlx vercel env pull .env.local
bun run vercel:deploy
```

#### Environment variables

...

### Configuring supabase

Create a new supabase project at [supabase.com](https://supabase.com) and then run `bun run supabase:link` to link your project to the local supabase instance. Run `bun run db:push` to push the database schema to the remote database.

In your Supabase project, navigate to [auth > URL configuration](https://app.supabase.com/project/_/auth/url-configuration) and set your main production URL (e.g. https://your-deployment-url.vercel.app) as the site url.

You will also need to configure your auth providers as required.

### Configure Stripe

Next, we'll need to configure [Stripe](https://stripe.com/) to handle test payments. If you don't already have a Stripe account, create one now.

For the following steps, make sure you have the ["Test Mode" toggle](https://stripe.com/docs/testing) switched on.

#### Create a Webhook

We need to create a webhook in the `Developers` section of Stripe. Pictured in the architecture diagram above, this webhook is the piece that connects Stripe to your Vercel Serverless Functions.

1. Click the "Add Endpoint" button on the [test Endpoints page](https://dashboard.stripe.com/test/webhooks).
1. Enter your production deployment URL followed by `/api/webhooks` for the endpoint URL. (e.g. `https://your-deployment-url.vercel.app/api/webhooks`)
1. Click `Select events` under the `Select events to listen to` heading.
1. Click `Select all events` in the `Select events to send` section.
1. Copy `Signing secret` as we'll need that in the next step (e.g `whsec_xxx`) (/!\ be careful not to copy the webook id we_xxxx).
1. In addition to the `NEXT_PUBLIC_STRIPE_PUBLISHABLE_KEY` and the `STRIPE_SECRET_KEY` we've set earlier during deployment, we need to add the webhook secret as `STRIPE_WEBHOOK_SECRET` env var.

Optionally, to speed up the setup, we have added a [fixtures file](fixtures/stripe-fixtures.json) to bootstrap test product and pricing data in your Stripe account. The [Stripe CLI](https://stripe.com/docs/stripe-cli#install) `fixtures` command executes a series of API requests defined in this JSON file. Simply run `stripe fixtures fixtures/stripe-fixtures.json`.

**Important:** Make sure that you've configured your Stripe webhook correctly and redeployed with all needed environment variables.

#### Configure the Stripe customer portal

1. Set your custom branding in the [settings](https://dashboard.stripe.com/settings/branding)
1. Configure the Customer Portal [settings](https://dashboard.stripe.com/test/settings/billing/portal)
1. Toggle on "Allow customers to update their payment methods"
1. Toggle on "Allow customers to update subscriptions"
1. Toggle on "Allow customers to cancel subscriptions"
1. Add the products and prices that you want
1. Set up the required business information and links

### Use the Stripe CLI to test webhooks

Use the [Stripe CLI](https://stripe.com/docs/stripe-cli) to [login to your Stripe account](https://stripe.com/docs/stripe-cli#login-account):

```bash
bun run stripe:login
```

This will print a URL to navigate to in your browser and provide access to your Stripe account.

Next, start local webhook forwarding:

```bash
bun run stripe:listen
```

Running this Stripe command will print a webhook secret (such as, `whsec_***`) to the console. Set `STRIPE_WEBHOOK_SECRET` to this value in your `.env.local` file. If you haven't already, you should also set `NEXT_PUBLIC_STRIPE_PUBLISHABLE_KEY` and `STRIPE_SECRET_KEY` in your `.env.local` file using the **test mode**(!) keys from your Stripe dashboard.

### Run the Next.js client

In a separate terminal, run the following command to start the development server:

```bash
bun dev
```

Note that webhook forwarding and the development server must be running concurrently in two separate terminals for the application to work correctly.

Finally, navigate to [http://localhost:3000](http://localhost:3000) in your browser to see the application rendered.

